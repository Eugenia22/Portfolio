# Построение ETL-пайплайна на Airflow

## Задача
Создать DAG в Airflow, который ежедневно будет считать показатели за вчерашний день и записывать их в таблицу. Параллельно должно обрабатываться две таблицы - feed_actions (данные по ленте новостей) и message_actions (данные по сервису обмена сообщениями). 
Полученные данные необходимо объединить в одну таблицу. В этой таблице посчитать все метрики в разрезе по полу, возрасту и ос. Финальный результат необходимо записать в отдельную таблицу в ClickHouse.

## Данные
Две таблица в ClickHouse c данными по ленте новостей и сервису сообщений, содержащие информацию по пользователям (уникальные id, пол, возраст, страна, город, ос, источник привлечения), их действиям (лайки и просмотры в ленте новостей, отправка и получение сообщений в сервисе сообщений), времени события, а так же информацию с уникальным номером поста в ленте новостей.

## Используемые библиотеки
pandas

# Навыки
sql, clickhouse, etl-процессы
